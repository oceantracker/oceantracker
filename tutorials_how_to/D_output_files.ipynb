{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output files\n",
    "\n",
    "[This note-book is in oceantracker/tutorials_how_to/]\n",
    "\n",
    "After running OceanTacker, output files are in the files are the folder given by parameters ./\"root_output_dir\"/\"output_file_base\".\n",
    "\n",
    "hint: FireFox will display json files in expandable strcture, other code also can do this\n",
    "\n",
    "The main files are:\n",
    "\n",
    "   *   **users_params_*.json**, a copy of the parameters as supplied by the user, useful in debugging or re-running.\n",
    "\n",
    "   *  **_runInfo.json** holds \n",
    "      \n",
    "         * file names of case  files\n",
    "\n",
    "         * information on computer used\n",
    "         \n",
    "         * code version, including git commit ID to enable rerunning with exactly the same version\n",
    "    \n",
    "   * **_caseInfo.json** files, have all the output files for each parallel case run (only 1 case in examples give so far), plus information about the run and data useful in plotting. Eg. \n",
    "\n",
    "      * full set of working parameters with defaults used\n",
    "\n",
    "      * timings of parts of code\n",
    "\n",
    "      * output_files, the names of all output files generated by the run separated by type.\n",
    "\n",
    "      * information about the hindcast, eg start date, end date, time step, ...\n",
    "      \n",
    "      * basic information from each class used in the computational pipeline\n",
    "\n",
    "   * **_caseLog_log.txt** has a copy of what appeared on the screen during the run \n",
    "\n",
    "   * **_tracks.nc** holds the particle tracks in a netcdf file, see below for code example on reading the tracks\n",
    "\n",
    "   * **_grid_outline.json** are the boundaries of hydrodynamic model's domain and islands, useful in plotting\n",
    "\n",
    "   * **_grid.nc** a netcdf of the hydo-model's grid and other information, useful in plotting and analysis\n",
    "\n",
    "   * **hindcast_variable_catalog.json**  holds info mapping file variables to internal variables \n",
    "\n",
    "   * **_events.nc** a netcdf output from events classes, which only writes output when events occur, eg. a particle entering or exiting given polygons.\n",
    "   \n",
    "   \n",
    "Time variables in these file are in seconds since 1970-01-01\n",
    "  \n",
    "Below list the files after running the minimal example. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/minimal_example\\hindcast_variable_catalog.json\n",
      "output/minimal_example\\minimal_example_caseInfo.json\n",
      "output/minimal_example\\minimal_example_caseLog.txt\n",
      "output/minimal_example\\minimal_example_grid.nc\n",
      "output/minimal_example\\minimal_example_release_groups.nc\n",
      "output/minimal_example\\minimal_example_run.txt\n",
      "output/minimal_example\\minimal_example_runInfo.json\n",
      "output/minimal_example\\minimal_example_tracks_compact.nc\n",
      "output/minimal_example\\user_given_params.json\n"
     ]
    }
   ],
   "source": [
    "# show a list of output files after running  minimal_example\n",
    "import glob\n",
    "for f in glob.glob('output/minimal_example/*'):\n",
    "    print(f) \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading particle tracks\n",
    "\n",
    "The below shows how to read the netcdf particle track output file into a python dictionary. The track file has a record of each of the particle properties, plus other useful information. The netcdf tracks file has a compact format, the below code reads this file into rectangular numpy  [ time, particle] arrays. Key variables are\n",
    ":\n",
    "\n",
    "* tracks['x']- the particle locations as a rectangular array of position vectors. With dimensions [ time, particle, vector component]. So that the 2D location is \n",
    "\n",
    "    ``x, y = tracks['x'][:,:,0], tracks['x'][:,:,1]``\n",
    "\n",
    "and for a 3D model the vertical position is z= tracks['x'][:,:,2]\n",
    "\n",
    "* tracks['time'] - array of time in seconds since 1970-1-1\n",
    "\n",
    "* tracks['date'] - array of dates as numpy datetime64[s]\n",
    "\n",
    "* tracks['status'] - the numerical codes of particle status, eg moving, dead etc as [ time, particle] array. The values of these status codes are also in the dictionary, eg tracks['status_stranded_by_tide'] = 3. \n",
    "\n",
    "* tracks['age'] - time series of each particles age, ie time since release in seconds. \n",
    "\n",
    "* tracks['IDrelease_group'] and tracks['IDpulse'] - id's of which release group particles where released from and which pulse within that group. These are  based indices and arrays of size particle, the total number of particles released during the run.\n",
    "\n",
    "The index within the \"particle\" dimension, is the individual particleID, ordered from first to last release across the entire model run.\n",
    "\n",
    "Note: For very large track files reading may fail, eg where variables exceed the 2-4Gb numpy array limit in Windows. To avoid this rerun using the tracks_writer setting \"time_steps_per_per_file\" to split the track file into files with given number of time steps.   Key variables in the dictionary are:\n",
    " \n",
    "\n",
    "The below also shows how read the hydrodynamic grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track data dict_keys(['status_unknown', 'status_bad_cord', 'status_cell_search_failed', 'status_notReleased', 'status_dead', 'status_outside_open_boundary', 'status_stationary', 'status_stranded_by_tide', 'status_on_bottom', 'status_moving', 'file_created', 'total_num_particles_released', 'time_steps_written', 'dimensions', 'status', 'age', 'user_release_groupID', 'hydro_model_gridID', 'particle_ID', 'ID', 'tide', 'particles_written_per_time_step', 'water_depth', 'IDrelease_group', 'num_part_released_so_far', 'A_Z_profile', 'x', 'IDpulse', 'time_released', 'dry_cell_index', 'time_step_range', 'x0', 'time', 'z'])\n",
      "Grid data dict_keys(['x', 'triangles', 'triangle_area', 'adjacency', 'node_type', 'is_boundary_triangle', 'water_depth', 'domain_outline_nodes', 'domain_outline_x', 'domain_masking_polygon', 'island_outline_nodes', 'island_outline_nodes_packed_ranges', 'grid_outline'])\n"
     ]
    }
   ],
   "source": [
    "# example of reading tracks file\n",
    "\n",
    "# read netcdf into dictionary\n",
    "from read_oceantracker.python import read_ncdf_output_files\n",
    "\n",
    "tracks =read_ncdf_output_files.read_particle_tracks_file('output/minimal_example\\minimal_example_tracks_compact.nc')\n",
    "print('Track data', tracks.keys())\n",
    "\n",
    "# read the hydro-dynamic grid file, useful in plotting\n",
    "grid =read_ncdf_output_files.read_grid_file('output/minimal_example\\minimal_example_grid.nc')\n",
    "print('Grid data',grid.keys())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data method\n",
    "\n",
    "Load data method, reads the netcdf, grid, and other  information needed to plot into a dictionary. This is the  recommended method for reading track output.  It uses the case_info file to locate all these files associated with the case run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_plot data dict_keys(['status_unknown', 'status_bad_cord', 'status_cell_search_failed', 'status_notReleased', 'status_dead', 'status_outside_open_boundary', 'status_stationary', 'status_stranded_by_tide', 'status_on_bottom', 'status_moving', 'file_created', 'total_num_particles_released', 'time_steps_written', 'dimensions', 'status', 'age', 'user_release_groupID', 'hydro_model_gridID', 'particle_ID', 'ID', 'tide', 'particles_written_per_time_step', 'water_depth', 'IDrelease_group', 'num_part_released_so_far', 'A_Z_profile', 'x', 'IDpulse', 'time_released', 'dry_cell_index', 'time_step_range', 'x0', 'time', 'z', 'grid', 'particle_status_flags', 'particle_release_groups', 'axis_lim'])\n"
     ]
    }
   ],
   "source": [
    "# load netcdf with grid and other useful info for plotting\n",
    "from read_oceantracker.python import load_output_files\n",
    "\n",
    "tracks_plot =load_output_files.load_track_data('output/minimal_example\\minimal_example_caseInfo.json')\n",
    "\n",
    "print('tracks_plot data', tracks_plot.keys())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanumapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
