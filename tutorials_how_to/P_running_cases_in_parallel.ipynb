{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run in parallel\n",
    "\n",
    "[This note-book is in oceantracker/tutorials_how_to/]\n",
    "\n",
    "Running in parallel can be done using the \"run with parameter dict.\" approach, or the helper class method.   Both build a base_case, which is the parameter defaults for each case, plus a list of  \"cases\" parameters specific to each parallel case. The output files for each case will be tagged with a case number, 0-n. The number of computationally active cases is be limited to be one less than the number of physical processes available.   \n",
    "\n",
    "The cases can be different, eg. have different release groups etc. A small number of settings must be the same for all cases, eg. setting \"root_output_folder\" must be the same for all cases. These settings will be taken from the base case.  Warnings are given if trying to use different values within case parameters. \n",
    "\n",
    "Is is strongly recommend to run parallel cases from within a python script, rather than notebooks which have limitations in Windows and may result in errors.\n",
    "\n",
    "Note: For large runs, memory to store the hindcast for each case may cause an error. To work around this, reduce the  size of the hindcast buffer, (\"reader\" class parameter \"time_buffer_size\"), or reduce the number of processors (setting \"processors\").\n",
    "\n",
    "## Example parallel release groups\n",
    "\n",
    "The below example runs a separate release group as its own parallel \"case\". \n",
    "\n",
    "To run in parallel on windows requires the run to be within a if __name__ == '__main__' block.  iPython note books ignores if __name__ == '__main__' statements, thus the below may not run when within a notebook in windows.  Use in notebooks also frequently gives \"file in use by another process\" errors.\n",
    "\n",
    "To avoid  this run parallel case as a script, eg. code in file  \"oceantracker/tutorials_how_to/P_running_cases_in_parallel.py\".\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parallel with helper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper ----------------------------------------------------------------------\n",
      "helper Starting OceanTracker helper class\n",
      "helper   - Starting run using helper class\n",
      "Main      Python version: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]\n",
      "Main >>> Warning: Oceantracker is not yet compatible with Python 3.11, as not all imported packages have been updated, eg netcdf4\n",
      "Main ----------------------------------------------------------------------\n",
      "Main OceanTracker starting main:\n",
      "Main     Starting package set up\n",
      "Main         -  Built OceanTracker package tree,\t  0.603 sec\n",
      "Main         -  Built OceanTracker sort name map,\t  0.000 sec\n",
      "Main     -  Done package set up to setup ClassImporter,\t  0.603 sec\n",
      "Main >>> Warning: Deleted contents of existing output dir\n",
      "Main Output is in dir \"f:\\H_Local_drive\\ParticleTracking\\oceantracker\\tutorials_how_to\\output\\parallel_test2\"\n",
      "Main       hint: see for copies of screen output and user supplied parameters, plus all other output\n",
      "Main     >>> Note: to help with debugging, parameters as given by user  are in \"user_given_params.json\"\n",
      "Main ----------------------------------------------------------------------\n",
      "Main  OceanTracker version 0.50.0010-2024-03-30 - preliminary setup\n",
      "Main   - Found input dir \"../demos/demo_hindcast/schsim3D\"\n",
      "Main   - found hydro-model files of type  \"SCHISM\"\n",
      "Main Cataloging hindcast with 1 files in dir ../demos/demo_hindcast/schsim3D\n",
      "Main     -  Cataloged hydro-model files/variables in time order,\t  0.008 sec\n",
      "Main >>> Note: No bottom_stress variable in in hydro-files, using near seabed velocity to calculate friction_velocity for resuspension\n",
      "Main     -  sorted hyrdo-model files in time order,\t  0.034 sec\n",
      "Main   - oceantracker:multiProcessing: processors:4\n",
      "Main   - parallel pool complete\n",
      "End --- Summary ----------------------------------------------------------\n",
      "End     >>> Note: Run summary with case file names in \"*_runInfo.json\"\n",
      "End     >>> Note: to help with debugging, parameters as given by user  are in \"user_given_params.json\"\n",
      "End >>> Note: No bottom_stress variable in in hydro-files, using near seabed velocity to calculate friction_velocity for resuspension\n",
      "End     >>> Note: Run summary with case file names in \"*_runInfo.json\"\n",
      "End >>> Warning: Oceantracker is not yet compatible with Python 3.11, as not all imported packages have been updated, eg netcdf4\n",
      "End >>> Warning: Deleted contents of existing output dir\n",
      "End ----------------------------------------------------------------------\n",
      "End ----------------------------------------------------------------------\n",
      "End OceanTracker summary:  elapsed time =0:00:17.406447\n",
      "End       Cases -   0 errors,   0 warnings,  12 notes, check above\n",
      "End       Main  -   0 errors,   2 warnings,   3 notes, check above\n",
      "End   Output in None\n",
      "End ----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# run in parallel using helper class method\n",
    "from oceantracker import main\n",
    "from  importlib import reload # force a reload to get around notebooks single name space\n",
    "reload(main)\n",
    "\n",
    "\n",
    "ot = main.OceanTracker()\n",
    "\n",
    "# setup base case\n",
    "# by default settings and classes are added to base case\n",
    "ot.settings(output_file_base= 'parallel_test2',      # name used as base for output files\n",
    "    root_output_dir='output',             #  output is put in dir   'root_output_dir'/'output_file_base'\n",
    "    time_step = 120,  #  2 min time step as seconds  \n",
    "    )\n",
    "\n",
    "ot.add_class('reader',input_dir= '../demos/demo_hindcast/schsim3D',  # folder to search for hindcast files, sub-dirs will, by default, also be searched\n",
    "                      file_mask=  'demo_hindcast_schisim3D*.nc')  # hindcast file mask\n",
    "\n",
    "# now put a release group with one point into case list\n",
    "# define the required release  points\n",
    "points = [  [1597682.1237, 5489972.7479],\n",
    "            [1598604.1667, 5490275.5488],\n",
    "            [1598886.4247, 5489464.0424],\n",
    "            [1597917.3387, 5489000],\n",
    "        ]\n",
    "# run each point release in parrallel\n",
    "for n, p in enumerate(points):\n",
    "    # add a release group with one point to case \"n\"\n",
    "    ot.add_class('release_groups',\n",
    "                case=n, # this adds release group to the n'th case to run in //\n",
    "                name ='mypoint'+str(n), # optional name for each group\n",
    "                points= p,  # needs to be 1, by 2 list for single 2D point\n",
    "                release_interval= 3600,           # seconds between releasing particles\n",
    "                pulse_size= 10,                   # number of particles released each release_interval\n",
    "                )\n",
    "\n",
    "# to run parallel in windows, must put run  call  inside the below \"if __name__ == '__main__':\" block\n",
    "if __name__ == '__main__':\n",
    "    # base case and case_list exist as attributes ot.params and ot.case_list\n",
    "    # run as parallel set of cases\n",
    "    case_info_files= ot.run()\n",
    "\n",
    "        \n",
    "    # NOTE for parallel runs case_info_files is a list, one for each case run\n",
    "    # so to load track files use    \n",
    "    # tracks = load_output_files.load_track_data(case_info_files[n])\n",
    "    #   where n is the case number 0,1,2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parallel using param. dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper ----------------------------------------------------------------------\n",
      "helper Starting OceanTracker helper class\n",
      "Main      Python version: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]\n",
      "Main >>> Warning: Oceantracker is not yet compatible with Python 3.11, as not all imported packages have been updated, eg netcdf4\n",
      "Main ----------------------------------------------------------------------\n",
      "Main OceanTracker starting main:\n",
      "Main     Starting package set up\n",
      "Main         -  Built OceanTracker package tree,\t  0.010 sec\n",
      "Main         -  Built OceanTracker sort name map,\t  0.000 sec\n",
      "Main     -  Done package set up to setup ClassImporter,\t  0.010 sec\n",
      "Main >>> Warning: Deleted contents of existing output dir\n",
      "Main Output is in dir \"f:\\H_Local_drive\\ParticleTracking\\oceantracker\\tutorials_how_to\\output\\parallel_test1\"\n",
      "Main       hint: see for copies of screen output and user supplied parameters, plus all other output\n",
      "Main     >>> Note: to help with debugging, parameters as given by user  are in \"user_given_params.json\"\n",
      "Main ----------------------------------------------------------------------\n",
      "Main  OceanTracker version 0.50.0010-2024-03-30 - preliminary setup\n",
      "Main   - Found input dir \"../demos/demo_hindcast/schsim3D\"\n",
      "Main   - found hydro-model files of type  \"SCHISM\"\n",
      "Main Cataloging hindcast with 1 files in dir ../demos/demo_hindcast/schsim3D\n",
      "Main     -  Cataloged hydro-model files/variables in time order,\t  0.009 sec\n",
      "Main >>> Note: No bottom_stress variable in in hydro-files, using near seabed velocity to calculate friction_velocity for resuspension\n",
      "Main     -  sorted hyrdo-model files in time order,\t  0.024 sec\n",
      "Main   - oceantracker:multiProcessing: processors:4\n",
      "Main   - parallel pool complete\n",
      "End --- Summary ----------------------------------------------------------\n",
      "End     >>> Note: Run summary with case file names in \"*_runInfo.json\"\n",
      "End     >>> Note: to help with debugging, parameters as given by user  are in \"user_given_params.json\"\n",
      "End >>> Note: No bottom_stress variable in in hydro-files, using near seabed velocity to calculate friction_velocity for resuspension\n",
      "End     >>> Note: Run summary with case file names in \"*_runInfo.json\"\n",
      "End >>> Warning: Oceantracker is not yet compatible with Python 3.11, as not all imported packages have been updated, eg netcdf4\n",
      "End >>> Warning: Deleted contents of existing output dir\n",
      "End ----------------------------------------------------------------------\n",
      "End ----------------------------------------------------------------------\n",
      "End OceanTracker summary:  elapsed time =0:00:16.965963\n",
      "End       Cases -   0 errors,   0 warnings,  12 notes, check above\n",
      "End       Main  -   0 errors,   2 warnings,   3 notes, check above\n",
      "End   Output in None\n",
      "End ----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# oceantracker parallel demo, run different release groups as parallel processes\n",
    "from oceantracker.main import OceanTracker\n",
    "\n",
    "# make instance of oceantracker to use to set parameters using code, then run\n",
    "ot = OceanTracker()\n",
    "\n",
    "# first build base case, params used for all cases\n",
    "params=dict(debug =True,\n",
    "    output_file_base= 'parallel_test1',      # name used as base for output files\n",
    "    root_output_dir= 'output',             #  output is put in dir   'root_output_dir'/'output_file_base'\n",
    "    time_step = 120,  #  2 min time step as seconds \n",
    "    ) \n",
    "params['reader']= dict(input_dir= '../demos/demo_hindcast/schsim3D',  # folder to search for hindcast files, sub-dirs will, by default, also be searched\n",
    "                      file_mask=  'demo_hindcast_schisim3D*.nc')\n",
    "\n",
    "# define the required release  points\n",
    "points = [  [1597682.1237, 5489972.7479],\n",
    "            [1598604.1667, 5490275.5488],\n",
    "            [1598886.4247, 5489464.0424],\n",
    "            [1597917.3387, 5489000],\n",
    "        ]\n",
    "\n",
    "# build a list of params for each case, with one release group for each point\n",
    "params['case_list'] =[]\n",
    "for n,p in enumerate(points):\n",
    "    # add one point as a release group to this case\n",
    "    d = dict( name= 'mypoint'+str(n),# better to give release group a unique name\n",
    "            points= [p],  # needs to be 1, by 2 list for single 2D point\n",
    "            release_interval= 3600,           # seconds between releasing particles\n",
    "            pulse_size= 10,                   # number of particles released each release_interval\n",
    "            )\n",
    "    case_param =dict(release_groups=[d]) # release group list of one or more releases\n",
    "    params['case_list'].append(case_param)\n",
    "\n",
    "# to run parallel in windows, must put run  call  inside the below \"if __name__ == '__main__':\" block\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # run as parallel set of cases\n",
    "    #    by default uses two less than the number of physical processors at one time, use setting \"processors\"\n",
    "    case_info_files= main.run(params)\n",
    "    \n",
    "    # NOTE for parallel runs case_info_files is a list, one for each case run\n",
    "    # so to load track files use    \n",
    "    # tracks = load_output_files.load_track_data(case_info_files[n])\n",
    "    #   where n is the case number 0,1,2...\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "developer-oceantracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
